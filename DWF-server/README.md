# Run the framework

## Use prebuilt docker image

 - simple run: run.sh (linux/ubuntu), run.bat (windows)
 - apply code changes and run: build_and_run.*
 - apply code changes and restart server: rebuild_and_run.*
 - apply code changes, clear database and restart server: rebuild_run_and_init.*

#### After running a script, the server is listening on port 4000

## Set up common Samba share for server and workers

At the moment, a Samba share can be used as a common storage space (where the feature data or input csvs can be shared between the workers and server). To set up your shared drive, use the following environment variables

    SMB_VOL=URL to your share
    SMB_DOMAIN=the domain name
    SMB_USER=your username
    SMB_PWD=your password
    
Once these variables are set, a new docker volume will be created and attached to the docker images, which can access these shared locations.

There are several starting scripts for the docker stack (batch and shell scripts), which will automatically ask these information from the user on start-up.

## Setting up default Kibana dashboard

The Deep-Water Framework comes with a default data visualization dashboard created with Kibana. To be able to use it, first its description needs to be imported into the underlying elasticsearch database. To import the dashboard open Kibana control panel after starting the dwf docker stack:

    http://localhost:5601/app/kibana#/management

Go to *Saved Objects*, select *Import*, and load the dashboard description file:

    DWF-server/templates/sample_dashboard.ndjson
    
Once it is loaded into Kibana, the *Results Dashboard* menu in the DWF server will open the dashboard visualizing the results of learnings.
    
# API endpoints

## `/register - POST`

- description:
  - clients send requests to this endpoint once at start to register
  - as a response, the server generates a unique hash that it can use for authentication later on

- request body:

      {
        "platform_info": {
          "node": "DESKTOP-1234ABC",
          "os": "Windows-10-10.0.12345-SP0",
          "cpu": {
            "brand": "AMD Ryzen 2 2400G with Radeon Vega Graphics",
            "clock_speed": "3.6000 GHz",
            "cores": 4
          },
          "gpu_json_str": "[Couldn't retrieve GPU information - probably not nvidia card.]",
          "memory": "30G"
        },
        "environment": {
          "PYTHON_SEED": 12345,
          "TEST": "test"
        }
      }

- response:

  - success:

        { "hash": "asd123" }, status: 200

    - hash (str): the client's hash code

  - error:

        { "message": "..." }, status: 400 or 403

## `/ping - POST`

- description:
  - clients send requests to this endpoint every 30s, signaling that they are alive

- request body:

      { "hash": "asd123" }

  - hash (str): hash generated by the server on register

- response:

  - success:

        { "hash": "asd123" }, status: 200

    - hash (str): the client's hash code

  - error:

        { "message": "..." }, status: 400

## `/get_task - POST`

- description:
  - clients send requests to this endpoint in every 30s, when they are available to complete a task

- request body:

      { "hash": "asd123" }

  - hash (str): hash generated by the server on register

- response:

  - success:

        { "task": {...} }, status: 200

    - task (obj | ""):

      - object if the server assigned a task to the client
      - empty string if there is no available task

  - error:

        { "message": "..." }, status: 400

## `/status - POST`

- description:
  - client sends request to this endpoint after every subtask completed thus the server can track the progress of the task that the client is currently working on

- request: 

      {
          "hash": "asd123",
          "progress": 0.42,
          "message": "DBH started..."
      }

  - hash (str): the client's hash code
  - progress (float): task completeness, between 0 and 1
  - message (str): any message to log to the server ui

- response:

  - success:

        { "hash": "asd123" }, satus: 200

    - hash (str): the client's hash code

  - error:

        { "message": "..." }, status: 403 / 404

## `/result - POST`

- description:

  - clients post the result of their tasks to this endpoint

- request: 

      {
          "hash": "asd123",
          "result": {...}
      }

  - hash (str): the client's hash code
  - task (obj | ""):

      - object if the task is a learning job
      - string if the task is an assembling job

- response:

  - success:

        { "hash": "asd123" }, satus: 200

    - hash (str): the client's hash code

  - error:

        { "message": "..." }, status: 400 / 404

## `/error - POST`

- description:
  - clients send requests to this endpoint when an error occurred with learning or assembling algorithms

- request body:

      { "hash": "asd123", "log": "..." }

  - hash (str): hash generated by the server on register
  - log (str): error message

- response:

  - success:

        { "hash": "asd123" }, status: 200

    - hash (str): the client's hash code

  - error:

        { "message": "..." }, status: 400
